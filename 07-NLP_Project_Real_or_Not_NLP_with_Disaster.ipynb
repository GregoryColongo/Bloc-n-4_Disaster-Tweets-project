{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "     |████████████████████████████████| 497.6 MB 5.4 kB/s             \n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     |████████████████████████████████| 1.4 MB 28.3 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "     |████████████████████████████████| 4.3 MB 59.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "     |████████████████████████████████| 2.1 MB 27.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.19.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 63.1 MB/s            \n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (59.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "     |████████████████████████████████| 289 kB 79.4 MB/s            \n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "     |████████████████████████████████| 156 kB 80.0 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=23cd3b70b7c4fe511bed4d5824968c4100e56347156cc886a0ba05e011bf4acc\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 werkzeug-2.0.3 wrapt-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 13:48:23.203086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-26 13:48:23.203145: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import pathlib \n",
    "import pandas as pd \n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with Pandas \n",
    "dataset = pd.read_csv(\"train-2.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take the columns we're interested in \n",
    "clean_dataset = dataset[[\"id\",\"text\", \"target\"]]\n",
    "clean_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-26 13:48:42.373508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-26 13:48:42.373557: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# installation of spicy\n",
    "!pip install spacy -q\n",
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading of the model\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Stop words \n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'please', 'move', 'indeed', 'eight', 'herein', 'was', 'bottom', 'only', 'me', 'several', 'n’t', 'became', 'show', 'seemed', 'which', 'hereafter', 'the', 'out', 'them', 'would', 'thence', 'no', 'twenty', 'almost', 'all', 'most', 'whereas', 'last', 'from', 'those', 'somewhere', 'their', 'three', 'are', 'through', 'until', 'within', 'do', 'get', 'might', 'itself', 'every', 'hereupon', 'made', 'wherein', 'except', 'him', 'hers', 'perhaps', 'nor', 'and', \"'s\", 'down', 'sometime', 'being', 'very', 'whom', 'did', 'if', 'along', 're', 'may', 'five', 'there', 'done', 'put', 'various', 'using', 'what', '’s', \"'ve\", 'another', 'name', 'we', 'after', 'go', 'two', 'towards', 'whoever', 'enough', 'than', 'own', 'under', 'behind', 'beside', 'whereby', 'least', 'namely', 'be', 'take', 'sometimes', 'i', 'something', 'everything', '’ll', 'next', 'whereafter', 'while', 'always', 'its', 'have', 'latterly', 'afterwards', 'us', 'keep', 'together', 'part', 'whose', 'nothing', 'about', 'as', 'does', 'none', 'back', '‘ve', '‘re', 'third', 'an', 'eleven', 'whole', 'really', 'on', 'serious', 'how', '’m', 'rather', 'see', 'themselves', 'nevertheless', 'make', 'per', 'yourselves', 'across', 'front', 'well', 'still', 'myself', 'each', 'anywhere', 'not', 'you', 'yours', 'thereby', 'regarding', 'when', 'nine', 'above', 'nobody', 'had', 'twelve', 'becoming', 'quite', 'thereupon', 'with', 'hereby', 'himself', 'cannot', 'noone', 'thus', 'same', 'why', 'once', 'thereafter', 'amount', 'hence', 'someone', 'is', 'anything', 'mostly', 'although', 'full', 'but', 'can', 'throughout', 'were', 'besides', 'ca', 'whence', 'seems', 'others', 'everyone', 'ours', 'mine', 'yourself', 'herself', \"'ll\", 'a', 'unless', 'fifty', 'few', 'whether', 'his', '’d', 'up', 'seem', 'elsewhere', 'therefore', 'ever', 'she', 'moreover', 'alone', 'give', 'too', 'they', 'everywhere', 'therein', '’re', 'often', 'whatever', 'hundred', 'such', \"'m\", '‘s', 'between', 'should', 'latter', 'further', 'call', 'other', 'whereupon', 'one', 'side', 'four', 'your', 'or', 'sixty', 'more', '‘d', 'say', 'thru', 'it', 'will', 'many', '‘m', 'since', 'anyhow', 'by', 'into', 'even', 'wherever', 'beyond', 'in', 'among', 'anyone', 'though', 'also', 'upon', 'off', 'due', 'used', 'fifteen', 'some', 'however', 'before', 'beforehand', 'am', 'becomes', 'much', 'that', 'for', 'of', \"'d\", 'so', 'anyway', 'amongst', 'must', 'else', 'yet', '‘ll', 'against', 'any', 'without', 'nowhere', 'our', 'via', 'otherwise', 'onto', 'first', 'somehow', 'never', 'whenever', 'over', 'seeming', \"'re\", 'top', 'doing', 'at', 'ourselves', 'below', 'empty', 'either', 'this', 'formerly', 'ten', 'former', 'he', 'again', 'could', 'forty', 'these', 'meanwhile', \"n't\", 'both', 'already', 'less', 'been', 'to', 'who', 'during', 'around', 'her', 'whither', 'neither', 'because', 'my', 'become', 'toward', 'has', 'now', 'six', 'n‘t', 'then', 'where', '’ve', 'here', 'just'}\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning of the text\n",
    "# Remove all non alphanumeric characters except whitespaces\n",
    "clean_dataset[\"text_clean\"] = clean_dataset[\"text\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
    "# remove double spaces and spaces at the beginning and end of strings\n",
    "clean_dataset[\"text_clean\"] = clean_dataset[\"text_clean\"].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
    "# remove stop words and replace everyword with their lemma\n",
    "clean_dataset[\"text_clean\"] = clean_dataset[\"text_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) & (token.text not in STOP_WORDS)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>got send photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>giant crane hold bridge collapse nearby home h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>ariaahrary thetawni control wild fire californ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>m194 0104 utc5 km s volcano hawaii httptcozdto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>police investigate ebike collide car little po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>late home raze northern california wildfire   ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...   \n",
       "1                Forest fire near La Ronge Sask. Canada   \n",
       "2     All residents asked to 'shelter in place' are ...   \n",
       "3     13,000 people receive #wildfires evacuation or...   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...   \n",
       "...                                                 ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "7611  Police investigating after an e-bike collided ...   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "                                             text_clean  target  \n",
       "0                  deed reason earthquake allah forgive       1  \n",
       "1                 forest fire near la ronge sask canada       1  \n",
       "2     resident ask shelter place notify officer evac...       1  \n",
       "3     13000 people receive wildfire evacuation order...       1  \n",
       "4     got send photo ruby alaska smoke wildfires pou...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  giant crane hold bridge collapse nearby home h...       1  \n",
       "7609  ariaahrary thetawni control wild fire californ...       1  \n",
       "7610  m194 0104 utc5 km s volcano hawaii httptcozdto...       1  \n",
       "7611  police investigate ebike collide car little po...       1  \n",
       "7612  late home raze northern california wildfire   ...       1  \n",
       "\n",
       "[7613 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset = clean_dataset[[\"text\",\"text_clean\",\"target\"]]\n",
    "clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000) # instanciate the tokenizer\n",
    "tokenizer.fit_on_texts(clean_dataset.text_clean)\n",
    "clean_dataset[\"review_encoded\"] = tokenizer.texts_to_sequences(clean_dataset.text_clean)\n",
    "clean_dataset[\"len_review\"] = clean_dataset[\"review_encoded\"].apply(lambda x: len(x))\n",
    "clean_dataset = clean_dataset[clean_dataset[\"len_review\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>target</th>\n",
       "      <th>review_encoded</th>\n",
       "      <th>len_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "      <td>[3663, 413, 171, 1383, 1944]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[117, 3, 159, 511, 5547, 5548, 1014]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1384, 446, 1706, 326, 5549, 295, 186, 1706, 3...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2301, 7, 2302, 70, 186, 283, 35]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>got send photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "      <td>[192, 179, 121, 5550, 1707, 172, 5551, 2303, 108]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                          text_clean  target  \\\n",
       "0               deed reason earthquake allah forgive       1   \n",
       "1              forest fire near la ronge sask canada       1   \n",
       "2  resident ask shelter place notify officer evac...       1   \n",
       "3  13000 people receive wildfire evacuation order...       1   \n",
       "4  got send photo ruby alaska smoke wildfires pou...       1   \n",
       "\n",
       "                                      review_encoded  len_review  \n",
       "0                       [3663, 413, 171, 1383, 1944]           5  \n",
       "1               [117, 3, 159, 511, 5547, 5548, 1014]           7  \n",
       "2  [1384, 446, 1706, 326, 5549, 295, 186, 1706, 3...          11  \n",
       "3                  [2301, 7, 2302, 70, 186, 283, 35]           7  \n",
       "4  [192, 179, 121, 5550, 1707, 172, 5551, 2303, 108]           9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3663,  413,  171, 1383, 1944,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#we will have to store all of our encoded texts into a single numpy array before \n",
    "#creating the tensorflow dataset. The problem is that not all our sequences are the same length, \n",
    "#this is where the tf.keras.preprocessing.sequence.pad_sequences comes in handy, \n",
    "#it will add zero padding at the end (padding=\"post\") of your sequences so they all have equal length.\n",
    "\n",
    "reviews_pad = tf.keras.preprocessing.sequence.pad_sequences(clean_dataset.review_encoded, padding=\"post\")\n",
    "reviews_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(25,), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds = tf.data.Dataset.from_tensor_slices((reviews_pad, clean_dataset.target.values))\n",
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "\n",
    "TAKE_SIZE = int(0.7*clean_dataset.shape[0])\n",
    "\n",
    "train_data = full_ds.take(TAKE_SIZE).shuffle(TAKE_SIZE)\n",
    "train_data = train_data.batch(64)\n",
    "\n",
    "test_data = full_ds.skip(TAKE_SIZE)\n",
    "test_data = test_data.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 205 2894  687 ...    0    0    0]\n",
      " [ 674  549  409 ...    0    0    0]\n",
      " [  44   96 2451 ...    0    0    0]\n",
      " ...\n",
      " [ 437  204  390 ...    0    0    0]\n",
      " [ 952  537  837 ...    0    0    0]\n",
      " [ 135  194  199 ...    0    0    0]], shape=(64, 25), dtype=int32) tf.Tensor(\n",
      "[0 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0], shape=(64,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# look a batch\n",
    "for review, star in train_data.take(1):\n",
    "  print(review, star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "vocab_size = tokenizer.num_words\n",
    "model = tf.keras.Sequential([\n",
    "                  # Couche d'Input Word Embedding           \n",
    "                  tf.keras.layers.Embedding(vocab_size+1, 8, input_shape=[reviews_pad.shape[1],],name=\"embedding\"),\n",
    "                  # Gobal average pooling\n",
    "                  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "                  # Couche Dense classique\n",
    "                  tf.keras.layers.Dense(16, activation='relu'),#resuluts no relevant with relu\n",
    "                  tf.keras.layers.Dense(8, activation='relu'),\n",
    "\n",
    "                  # Couche de sortie avec le nombre de neurones en sortie égale au nombre de classe avec fonction softmax\n",
    "                  tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 8)             80008     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 8)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                144       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,297\n",
      "Trainable params: 80,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation of model\n",
    "optimizer= tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.1484992101105846, 1: 2.851500789889416}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = dict(1/(clean_dataset.target).value_counts()/sum(1/(clean_dataset.target).value_counts())*5)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0340 - mean_absolute_error: 0.1081 - val_loss: 0.2027 - val_mean_absolute_error: 0.3424\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.0999 - val_loss: 0.2075 - val_mean_absolute_error: 0.3396\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0273 - mean_absolute_error: 0.0892 - val_loss: 0.2114 - val_mean_absolute_error: 0.3431\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0248 - mean_absolute_error: 0.0834 - val_loss: 0.2192 - val_mean_absolute_error: 0.3447\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0235 - mean_absolute_error: 0.0795 - val_loss: 0.2249 - val_mean_absolute_error: 0.3468\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0214 - mean_absolute_error: 0.0733 - val_loss: 0.2249 - val_mean_absolute_error: 0.3423\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - mean_absolute_error: 0.0689 - val_loss: 0.2268 - val_mean_absolute_error: 0.3390\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0189 - mean_absolute_error: 0.0641 - val_loss: 0.2304 - val_mean_absolute_error: 0.3395\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0186 - mean_absolute_error: 0.0643 - val_loss: 0.2352 - val_mean_absolute_error: 0.3457\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0170 - mean_absolute_error: 0.0577 - val_loss: 0.2354 - val_mean_absolute_error: 0.3409\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0164 - mean_absolute_error: 0.0561 - val_loss: 0.2387 - val_mean_absolute_error: 0.3402\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - mean_absolute_error: 0.0591 - val_loss: 0.2474 - val_mean_absolute_error: 0.3511\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - mean_absolute_error: 0.0506 - val_loss: 0.2459 - val_mean_absolute_error: 0.3457\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - mean_absolute_error: 0.0476 - val_loss: 0.2495 - val_mean_absolute_error: 0.3471\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - mean_absolute_error: 0.0493 - val_loss: 0.2519 - val_mean_absolute_error: 0.3497\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0135 - mean_absolute_error: 0.0449 - val_loss: 0.2517 - val_mean_absolute_error: 0.3438\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0134 - mean_absolute_error: 0.0453 - val_loss: 0.2514 - val_mean_absolute_error: 0.3459\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0132 - mean_absolute_error: 0.0450 - val_loss: 0.2552 - val_mean_absolute_error: 0.3476\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0128 - mean_absolute_error: 0.0458 - val_loss: 0.2624 - val_mean_absolute_error: 0.3497\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0124 - mean_absolute_error: 0.0435 - val_loss: 0.2645 - val_mean_absolute_error: 0.3558\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0121 - mean_absolute_error: 0.0424 - val_loss: 0.2648 - val_mean_absolute_error: 0.3449\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0126 - mean_absolute_error: 0.0455 - val_loss: 0.2602 - val_mean_absolute_error: 0.3433\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0119 - mean_absolute_error: 0.0414 - val_loss: 0.2661 - val_mean_absolute_error: 0.3457\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0115 - mean_absolute_error: 0.0384 - val_loss: 0.2628 - val_mean_absolute_error: 0.3421\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0118 - mean_absolute_error: 0.0385 - val_loss: 0.2719 - val_mean_absolute_error: 0.3569\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0113 - mean_absolute_error: 0.0401 - val_loss: 0.2638 - val_mean_absolute_error: 0.3466\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0114 - mean_absolute_error: 0.0411 - val_loss: 0.2663 - val_mean_absolute_error: 0.3454\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0126 - mean_absolute_error: 0.0452 - val_loss: 0.2664 - val_mean_absolute_error: 0.3451\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0110 - mean_absolute_error: 0.0368 - val_loss: 0.2771 - val_mean_absolute_error: 0.3543\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0108 - mean_absolute_error: 0.0369 - val_loss: 0.2769 - val_mean_absolute_error: 0.3603\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0108 - mean_absolute_error: 0.0385 - val_loss: 0.2716 - val_mean_absolute_error: 0.3547\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0110 - mean_absolute_error: 0.0398 - val_loss: 0.2817 - val_mean_absolute_error: 0.3589\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0109 - mean_absolute_error: 0.0389 - val_loss: 0.2692 - val_mean_absolute_error: 0.3467\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_absolute_error: 0.0355 - val_loss: 0.2780 - val_mean_absolute_error: 0.3556\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0331 - val_loss: 0.2748 - val_mean_absolute_error: 0.3517\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0101 - mean_absolute_error: 0.0330 - val_loss: 0.2792 - val_mean_absolute_error: 0.3508\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0101 - mean_absolute_error: 0.0340 - val_loss: 0.2819 - val_mean_absolute_error: 0.3571\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_error: 0.0328 - val_loss: 0.2790 - val_mean_absolute_error: 0.3474\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0349 - val_loss: 0.2898 - val_mean_absolute_error: 0.3634\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0099 - mean_absolute_error: 0.0334 - val_loss: 0.2814 - val_mean_absolute_error: 0.3511\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_absolute_error: 0.0368 - val_loss: 0.2790 - val_mean_absolute_error: 0.3536\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_error: 0.0350 - val_loss: 0.2780 - val_mean_absolute_error: 0.3540\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_absolute_error: 0.0323 - val_loss: 0.2735 - val_mean_absolute_error: 0.3491\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_absolute_error: 0.0326 - val_loss: 0.2770 - val_mean_absolute_error: 0.3529\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0099 - mean_absolute_error: 0.0339 - val_loss: 0.2791 - val_mean_absolute_error: 0.3526\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_absolute_error: 0.0320 - val_loss: 0.2744 - val_mean_absolute_error: 0.3494\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0322 - val_loss: 0.2778 - val_mean_absolute_error: 0.3499\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_error: 0.0323 - val_loss: 0.2797 - val_mean_absolute_error: 0.3504\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_error: 0.0316 - val_loss: 0.2756 - val_mean_absolute_error: 0.3523\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0110 - mean_absolute_error: 0.0378 - val_loss: 0.2753 - val_mean_absolute_error: 0.3508\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0324 - val_loss: 0.2761 - val_mean_absolute_error: 0.3533\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0315 - val_loss: 0.2854 - val_mean_absolute_error: 0.3518\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0097 - mean_absolute_error: 0.0325 - val_loss: 0.2772 - val_mean_absolute_error: 0.3516\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0316 - val_loss: 0.2790 - val_mean_absolute_error: 0.3503\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0329 - val_loss: 0.2788 - val_mean_absolute_error: 0.3508\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0319 - val_loss: 0.2782 - val_mean_absolute_error: 0.3507\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0309 - val_loss: 0.2806 - val_mean_absolute_error: 0.3506\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0309 - val_loss: 0.2806 - val_mean_absolute_error: 0.3505\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0290 - val_loss: 0.2781 - val_mean_absolute_error: 0.3539\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_error: 0.0382 - val_loss: 0.2882 - val_mean_absolute_error: 0.3532\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0393 - val_loss: 0.2839 - val_mean_absolute_error: 0.3554\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0315 - val_loss: 0.2918 - val_mean_absolute_error: 0.3571\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0321 - val_loss: 0.2761 - val_mean_absolute_error: 0.3499\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0296 - val_loss: 0.2955 - val_mean_absolute_error: 0.3627\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.0283 - val_loss: 0.2849 - val_mean_absolute_error: 0.3543\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0289 - val_loss: 0.2880 - val_mean_absolute_error: 0.3540\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0278 - val_loss: 0.2816 - val_mean_absolute_error: 0.3558\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.0289 - val_loss: 0.2856 - val_mean_absolute_error: 0.3509\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_error: 0.0281 - val_loss: 0.2919 - val_mean_absolute_error: 0.3521\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_error: 0.0285 - val_loss: 0.2856 - val_mean_absolute_error: 0.3524\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0280 - val_loss: 0.2839 - val_mean_absolute_error: 0.3582\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0309 - val_loss: 0.2860 - val_mean_absolute_error: 0.3549\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0290 - val_loss: 0.2972 - val_mean_absolute_error: 0.3598\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0302 - val_loss: 0.2863 - val_mean_absolute_error: 0.3522\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_error: 0.0292 - val_loss: 0.2800 - val_mean_absolute_error: 0.3556\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0318 - val_loss: 0.2936 - val_mean_absolute_error: 0.3569\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_error: 0.0285 - val_loss: 0.2903 - val_mean_absolute_error: 0.3559\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_error: 0.0275 - val_loss: 0.2837 - val_mean_absolute_error: 0.3514\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0302 - val_loss: 0.2910 - val_mean_absolute_error: 0.3525\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0336 - val_loss: 0.3018 - val_mean_absolute_error: 0.3665\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_absolute_error: 0.0322 - val_loss: 0.2867 - val_mean_absolute_error: 0.3528\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.0324 - val_loss: 0.2959 - val_mean_absolute_error: 0.3569\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0302 - val_loss: 0.2908 - val_mean_absolute_error: 0.3575\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0086 - mean_absolute_error: 0.0279 - val_loss: 0.3035 - val_mean_absolute_error: 0.3637\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0088 - mean_absolute_error: 0.0292 - val_loss: 0.2926 - val_mean_absolute_error: 0.3548\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0087 - mean_absolute_error: 0.0289 - val_loss: 0.2896 - val_mean_absolute_error: 0.3501\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0090 - mean_absolute_error: 0.0311 - val_loss: 0.2823 - val_mean_absolute_error: 0.3508\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0082 - mean_absolute_error: 0.0269 - val_loss: 0.2878 - val_mean_absolute_error: 0.3483\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0086 - mean_absolute_error: 0.0267 - val_loss: 0.2886 - val_mean_absolute_error: 0.3502\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0088 - mean_absolute_error: 0.0286 - val_loss: 0.3023 - val_mean_absolute_error: 0.3619\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0087 - mean_absolute_error: 0.0272 - val_loss: 0.2954 - val_mean_absolute_error: 0.3572\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0085 - mean_absolute_error: 0.0255 - val_loss: 0.2822 - val_mean_absolute_error: 0.3517\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0087 - mean_absolute_error: 0.0290 - val_loss: 0.3020 - val_mean_absolute_error: 0.3628\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0085 - mean_absolute_error: 0.0271 - val_loss: 0.2949 - val_mean_absolute_error: 0.3573\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_error: 0.0266 - val_loss: 0.3060 - val_mean_absolute_error: 0.3680\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0088 - mean_absolute_error: 0.0300 - val_loss: 0.2876 - val_mean_absolute_error: 0.3520\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0085 - mean_absolute_error: 0.0256 - val_loss: 0.2948 - val_mean_absolute_error: 0.3541\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.0085 - mean_absolute_error: 0.0260 - val_loss: 0.2885 - val_mean_absolute_error: 0.3531\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0085 - mean_absolute_error: 0.0294 - val_loss: 0.2895 - val_mean_absolute_error: 0.3498\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0088 - mean_absolute_error: 0.0302 - val_loss: 0.3061 - val_mean_absolute_error: 0.3631\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du modèle \n",
    "history = model.fit(train_data, \n",
    "                    epochs=100, \n",
    "                    validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization of the training process on the loss function \n",
    "plt.plot(history.history[\"loss\"], color=\"b\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"r\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion (to be filled in) / Loss value O,3 / to be affined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
